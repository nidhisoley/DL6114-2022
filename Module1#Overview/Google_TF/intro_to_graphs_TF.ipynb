{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7ITxKLUkX0v"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors.\n",
    "\n",
    "<b> Few content cells are modified or added by the instructor, when needed. Some links were removed and you can get the orginal copy from the below GitHub</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-12-08T17:16:55.071822Z",
     "iopub.status.busy": "2021-12-08T17:16:55.071208Z",
     "iopub.status.idle": "2021-12-08T17:16:55.073652Z",
     "shell.execute_reply": "2021-12-08T17:16:55.074047Z"
    },
    "id": "yOYx6tzSnWQ3"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xgB0Oz5eGSQ"
   },
   "source": [
    "# Introduction to graphs and tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4zzZVZtQb1w"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/intro_to_graphs\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBKqnXI9GOax"
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this guide, you'll learn how TensorFlow allows you to make simple changes to your code to get graphs, how graphs are stored and represented, and how you can use them to accelerate your models.\n",
    "\n",
    "Note: For those of you who are only familiar with TensorFlow 1.x, this guide demonstrates a very different view of graphs.\n",
    "\n",
    "**This is a big-picture overview that covers how `tf.function` allows you to switch from eager execution to graph execution.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0DdlfacAdTZ"
   },
   "source": [
    "### What are graphs?\n",
    "\n",
    "In the previous three guides, you ran TensorFlow **eagerly**. This means TensorFlow operations are executed by Python, operation by operation, and returning results back to Python.\n",
    "\n",
    "While eager execution has several unique advantages, graph execution enables portability outside Python and tends to offer better performance. **Graph execution** means that tensor computations are executed as a *TensorFlow graph*, sometimes referred to as a `tf.Graph` or simply a \"graph.\"\n",
    "\n",
    "**Graphs are data structures that contain a set of `tf.Operation` objects, which represent units of computation; and `tf.Tensor` objects, which represent the units of data that flow between operations.** They are defined in a `tf.Graph` context. Since these graphs are data structures, they can be saved, run, and restored all without the original Python code.\n",
    "\n",
    "This is what a TensorFlow graph representing a two-layer neural network looks like when visualized in TensorBoard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Relu activation function](https://iq.opengenus.org/relu-activation/#:~:text=The%20rectified%20linear%20activation%20function%20or%20ReLU%20is,in%20Convolutional%20Neural%20Networks%20%28CNNs%29%20%26%20Multilayer%20perceptrons.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvQ5aBuRGT1o"
   },
   "source": [
    "<img alt=\"A simple TensorFlow graph\" src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/intro_to_graphs/two-layer-network.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHpY3avXGITP"
   },
   "source": [
    "### The benefits of graphs\n",
    "\n",
    "With a graph, you have a great deal of flexibility.  You can use your TensorFlow graph in environments that don't have a Python interpreter, like mobile applications, embedded devices, and backend servers.  \n",
    "\n",
    "Graphs are also easily optimized, allowing the compiler to do transformations like:\n",
    "\n",
    "* Statically infer the value of tensors by folding constant nodes in your computation *(\"constant folding\")*.\n",
    "* Separate sub-parts of a computation that are independent and split them between threads or devices.\n",
    "* Simplify arithmetic operations by eliminating common subexpressions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1x1EOD9GjnB"
   },
   "source": [
    "In short, graphs are extremely useful and let your TensorFlow run **fast**, run **in parallel**, and run efficiently **on multiple devices**.\n",
    "\n",
    "However, you still want to define your machine learning models (or other computations) in Python for convenience, and then automatically construct graphs when you need them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-6Qi0thw2i9"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "goZwOXp_xyQj",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "info=\"\"\"\n",
    "0 = all messages are logged (default behavior)\n",
    "1 = INFO messages are not printed\n",
    "2 = INFO and WARNING messages are not printed\n",
    "3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\"\"\"\n",
    "\n",
    "import timeit\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSZebVuWxDXu"
   },
   "source": [
    "## Taking advantage of graphs\n",
    "\n",
    "You create and run a graph in TensorFlow by using `tf.function`, either as a direct call or as a decorator. `tf.function` takes a regular function as input and returns a `Function`. **A `Function` is a Python callable that builds TensorFlow graphs from the Python function. You use a `Function` in the same way as its Python equivalent.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function matmul in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "matmul(a, b, transpose_a=False, transpose_b=False, adjoint_a=False, adjoint_b=False, a_is_sparse=False, b_is_sparse=False, output_type=None, name=None)\n",
      "    Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "    \n",
      "    The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "    where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
      "    and any further outer dimensions specify matching batch size.\n",
      "    \n",
      "    Both matrices must be of the same type. The supported types are:\n",
      "    `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "    `complex64`, `complex128`.\n",
      "    \n",
      "    Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "    the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "    by default.\n",
      "    \n",
      "    If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "    multiplication algorithm can be used by setting the corresponding\n",
      "    `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "    This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "    datatypes `bfloat16` or `float32`.\n",
      "    \n",
      "    A simple 2-D tensor matrix multiplication:\n",
      "    \n",
      "    >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "    >>> a  # 2-D tensor\n",
      "    <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]], dtype=int32)>\n",
      "    >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "    >>> b  # 2-D tensor\n",
      "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "    array([[ 7,  8],\n",
      "           [ 9, 10],\n",
      "           [11, 12]], dtype=int32)>\n",
      "    >>> c = tf.matmul(a, b)\n",
      "    >>> c  # `a` * `b`\n",
      "    <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "    array([[ 58,  64],\n",
      "           [139, 154]], dtype=int32)>\n",
      "    \n",
      "    A batch matrix multiplication with batch shape [2]:\n",
      "    \n",
      "    >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
      "    >>> a  # 3-D tensor\n",
      "    <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
      "    array([[[ 1,  2,  3],\n",
      "            [ 4,  5,  6]],\n",
      "           [[ 7,  8,  9],\n",
      "            [10, 11, 12]]], dtype=int32)>\n",
      "    >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
      "    >>> b  # 3-D tensor\n",
      "    <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
      "    array([[[13, 14],\n",
      "            [15, 16],\n",
      "            [17, 18]],\n",
      "           [[19, 20],\n",
      "            [21, 22],\n",
      "            [23, 24]]], dtype=int32)>\n",
      "    >>> c = tf.matmul(a, b)\n",
      "    >>> c  # `a` * `b`\n",
      "    <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
      "    array([[[ 94, 100],\n",
      "            [229, 244]],\n",
      "           [[508, 532],\n",
      "            [697, 730]]], dtype=int32)>\n",
      "    \n",
      "    Since python >= 3.5 the @ operator is supported\n",
      "    (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
      "    it simply calls the `tf.matmul()` function, so the following lines are\n",
      "    equivalent:\n",
      "    \n",
      "    >>> d = a @ b @ [[10], [11]]\n",
      "    >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
      "    \n",
      "    Args:\n",
      "      a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
      "        `complex64`, `complex128` and rank > 1.\n",
      "      b: `tf.Tensor` with same type and rank as `a`.\n",
      "      transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "      transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "      adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "        multiplication.\n",
      "      adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "        multiplication.\n",
      "      a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
      "        **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "        that assume most values in `a` are zero.\n",
      "        See `tf.sparse.sparse_dense_matmul`\n",
      "        for some support for `tf.sparse.SparseTensor` multiplication.\n",
      "      b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
      "        **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
      "        that assume most values in `a` are zero.\n",
      "        See `tf.sparse.sparse_dense_matmul`\n",
      "        for some support for `tf.sparse.SparseTensor` multiplication.\n",
      "      output_type: The output datatype if needed. Defaults to None in which case\n",
      "        the output_type is the same as input type. Currently only works when input\n",
      "        tensors are type (u)int8 and output_type can be int32.\n",
      "      name: Name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
      "      is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "      transpose or adjoint attributes are `False`:\n",
      "    \n",
      "      `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
      "      for all indices `i`, `j`.\n",
      "    \n",
      "      Note: This is matrix product, not element-wise product.\n",
      "    \n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
      "        `adjoint_b` are both set to `True`.\n",
      "      TypeError: If output_type is specified but the types of `a`, `b` and\n",
      "        `output_type` is not (u)int8, (u)int8 and int32.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HKbLeJ1y0Umi",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]]\n"
     ]
    }
   ],
   "source": [
    "# Define a Python function.\n",
    "def a_regular_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# `a_function_that_uses_a_graph` is a TensorFlow `Function`.\n",
    "a_function_that_uses_a_graph = tf.function(a_regular_function)\n",
    "\n",
    "# Make some tensors.\n",
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[2.0], [3.0]])\n",
    "b1 = tf.constant(4.0)\n",
    "\n",
    "orig_value = a_regular_function(x1, y1, b1).numpy()\n",
    "# Call a `Function` like a Python function.\n",
    "tf_function_value = a_function_that_uses_a_graph(x1, y1, b1).numpy()\n",
    "print(orig_value == tf_function_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNvuAYpdrTOf"
   },
   "source": [
    "On the outside, a `Function` looks like a regular function you write using TensorFlow operations. Underneath, however, it is *very different*. A `Function` **encapsulates several `tf.Graph`s behind one API.** That is how `Function` is able to give you the benefits of graph execution, like speed and deployability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MT7U8ozok0gV"
   },
   "source": [
    "`tf.function` applies to a function *and all other functions it calls*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rpz08iLplm9F",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inner_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# Use the decorator to make `outer_function` a `Function`.\n",
    "@tf.function\n",
    "def outer_function(x):\n",
    "  y = tf.constant([[2.0], [3.0]])\n",
    "  b = tf.constant(4.0)\n",
    "\n",
    "  return inner_function(x, y, b)\n",
    "\n",
    "# Note that the callable will create a graph that\n",
    "# includes `inner_function` as well as `outer_function`.\n",
    "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P88fOr88qgCj"
   },
   "source": [
    "If you have used TensorFlow 1.x, you will notice that at no time did you need to define a `Placeholder` or `tf.Session`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfeKf0Nr1OEK"
   },
   "source": [
    "### Converting Python functions to graphs\n",
    "\n",
    "Any function you write with TensorFlow will contain a mixture of built-in TF operations and Python logic, such as `if-then` clauses, loops, `break`, `return`, `continue`, and more. While TensorFlow operations are easily captured by a `tf.Graph`, Python-specific logic needs to undergo an extra step in order to become part of the graph. `tf.function` uses a library called AutoGraph (`tf.autograph`) to convert Python code into graph-generating code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PFObpff1BMEb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First branch, with graph: 1\n",
      "Second branch, with graph: 0\n"
     ]
    }
   ],
   "source": [
    "def simple_relu(x):\n",
    "  if tf.greater(x, 0):\n",
    "    return x\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "# `tf_simple_relu` is a TensorFlow `Function` that wraps `simple_relu`.\n",
    "tf_simple_relu = tf.function(simple_relu)\n",
    "\n",
    "print(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\n",
    "print(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hO4DBUNZBMwQ"
   },
   "source": [
    "Though it is unlikely that you will need to view graphs directly, you can inspect the outputs to check the exact results. These are not easy to read, so no need to look too carefully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lAKaat3w0gnn",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__simple_relu(x):\n",
      "    with ag__.FunctionScope('simple_relu', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (do_return, retval_)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal do_return, retval_\n",
      "            (do_return, retval_) = vars_\n",
      "\n",
      "        def if_body():\n",
      "            nonlocal do_return, retval_\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = ag__.ld(x)\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "\n",
      "        def else_body():\n",
      "            nonlocal do_return, retval_\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = 0\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "        ag__.if_stmt(ag__.converted_call(ag__.ld(tf).greater, (ag__.ld(x), 0), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the graph-generating output of AutoGraph.\n",
    "print(tf.autograph.to_code(simple_relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8x6RAqza1UWf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node {\n",
      "  name: \"x\"\n",
      "  op: \"Placeholder\"\n",
      "  attr {\n",
      "    key: \"_user_specified_name\"\n",
      "    value {\n",
      "      s: \"x\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Greater/y\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "        }\n",
      "        int_val: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Greater\"\n",
      "  op: \"Greater\"\n",
      "  input: \"x\"\n",
      "  input: \"Greater/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond\"\n",
      "  op: \"StatelessIf\"\n",
      "  input: \"Greater\"\n",
      "  input: \"x\"\n",
      "  attr {\n",
      "    key: \"Tcond\"\n",
      "    value {\n",
      "      type: DT_BOOL\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tin\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tout\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_BOOL\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_lower_using_switch_merge\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_read_only_resource_inputs\"\n",
      "    value {\n",
      "      list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"else_branch\"\n",
      "    value {\n",
      "      func {\n",
      "        name: \"cond_false_64\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"output_shapes\"\n",
      "    value {\n",
      "      list {\n",
      "        shape {\n",
      "        }\n",
      "        shape {\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"then_branch\"\n",
      "    value {\n",
      "      func {\n",
      "        name: \"cond_true_63\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond/Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_BOOL\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond/Identity_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond/Identity_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "library {\n",
      "  function {\n",
      "    signature {\n",
      "      name: \"cond_false_64\"\n",
      "      input_arg {\n",
      "        name: \"cond_placeholder\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity\"\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity_1\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_1\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_2\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_INT32\n",
      "            tensor_shape {\n",
      "            }\n",
      "            int_val: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_3\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const_3:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_4\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_INT32\n",
      "            tensor_shape {\n",
      "            }\n",
      "            int_val: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity_1\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const_4:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity\"\n",
      "      value: \"cond/Identity:output:0\"\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity_1\"\n",
      "      value: \"cond/Identity_1:output:0\"\n",
      "    }\n",
      "    attr {\n",
      "      key: \"_construction_context\"\n",
      "      value {\n",
      "        s: \"kEagerRuntime\"\n",
      "      }\n",
      "    }\n",
      "    arg_attr {\n",
      "      key: 0\n",
      "      value {\n",
      "        attr {\n",
      "          key: \"_output_shapes\"\n",
      "          value {\n",
      "            list {\n",
      "              shape {\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  function {\n",
      "    signature {\n",
      "      name: \"cond_true_63\"\n",
      "      input_arg {\n",
      "        name: \"cond_identity_1_x\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity\"\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity_1\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity_1\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond_identity_1_x\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity\"\n",
      "      value: \"cond/Identity:output:0\"\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity_1\"\n",
      "      value: \"cond/Identity_1:output:0\"\n",
      "    }\n",
      "    attr {\n",
      "      key: \"_construction_context\"\n",
      "      value {\n",
      "        s: \"kEagerRuntime\"\n",
      "      }\n",
      "    }\n",
      "    arg_attr {\n",
      "      key: 0\n",
      "      value {\n",
      "        attr {\n",
      "          key: \"_output_shapes\"\n",
      "          value {\n",
      "            list {\n",
      "              shape {\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "versions {\n",
      "  producer: 898\n",
      "  min_consumer: 12\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the graph itself.\n",
    "print(tf_simple_relu.get_concrete_function(tf.constant(1)).graph.as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZ4Ieg6tBE6l"
   },
   "source": [
    "Most of the time, `tf.function` will work without  special considerations.  However, there are some caveats, and the tf.function guide can help here, as well as the complete AutoGraph reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIpc_jfjEZEg"
   },
   "source": [
    "### Polymorphism: one `Function`, many graphs\n",
    "\n",
    "A `tf.Graph` is specialized to a specific type of inputs (for example, tensors with a specific [`dtype`](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType) or objects with the same [`id()`](https://docs.python.org/3/library/functions.html#id])).\n",
    "\n",
    "Each time you invoke a `Function` with new `dtypes` and shapes in its arguments, `Function` creates a new `tf.Graph` for the new arguments. The `dtypes` and shapes of a `tf.Graph`'s inputs are known as an **input signature** or just a **signature**.\n",
    "\n",
    "The `Function` stores the `tf.Graph` corresponding to that signature in a `ConcreteFunction`. **A `ConcreteFunction` is a wrapper around a `tf.Graph`.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LOASwhbvIv_T",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.5, shape=(), dtype=float32)\n",
      "tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([3. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def my_relu(x):\n",
    "  return tf.maximum(0., x)\n",
    "\n",
    "# `my_relu` creates new graphs as it observes more signatures.\n",
    "print(my_relu(tf.constant(5.5)))\n",
    "print(my_relu([1, -1]))\n",
    "print(my_relu(tf.constant([3., -3.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qRtw7R4KL9X"
   },
   "source": [
    "If the `Function` has already been called with that signature, `Function` does not create a new `tf.Graph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TjjbnL5OKNDP",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# These two calls do *not* create new graphs.\n",
    "print(my_relu(tf.constant(-2.5))) # Signature matches `tf.constant(5.5)`.\n",
    "print(my_relu(tf.constant([-1., 1.]))) # Signature matches `tf.constant([3., -3.])`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UohRmexhIpvQ"
   },
   "source": [
    "Because it's backed by multiple graphs, a `Function` is **polymorphic**. That enables it to support more input types than a single `tf.Graph` could represent, as well as to optimize each `tf.Graph` for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dxzqebDYFmLy",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=()\n",
      "  Returns:\n",
      "    float32 Tensor, shape=()\n",
      "\n",
      "my_relu(x=[1, -1])\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n",
      "\n",
      "my_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=(2,)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n"
     ]
    }
   ],
   "source": [
    "# There are three `ConcreteFunction`s (one for each graph) in `my_relu`.\n",
    "# The `ConcreteFunction` also knows the return type and shape!\n",
    "print(my_relu.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V11zkxU22XeD"
   },
   "source": [
    "## Using `tf.function`\n",
    "\n",
    "So far, you've learned how to convert a Python function into a graph simply by using `tf.function` as a decorator or wrapper. But in practice, getting `tf.function` to work correctly can be tricky! In the following sections, you'll learn how you can make your code work as expected with `tf.function`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yp_n0B5-P0RU"
   },
   "source": [
    "### Graph execution vs. eager execution\n",
    "\n",
    "The code in a `Function` can be executed both eagerly and as a graph. By default, `Function` executes its code as a graph:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_R0BOvBFxqVZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
    "  return tf.reduce_mean(sq_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zikMVPGhmDET",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([8 0 5 5 3], shape=(5,), dtype=int32)\n",
      "tf.Tensor([2 4 3 6 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "07r08Dh158ft",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=13>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyZNCRcQorGO"
   },
   "source": [
    "To verify that your `Function`'s graph is doing the same computation as its equivalent Python function, you can make it execute eagerly with `tf.config.run_functions_eagerly(True)`.  This is a switch that **turns off `Function`'s ability to create and run graphs**, instead executing the code normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lKoF6NjPoI8w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9ZLqTyn0oKeM",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=13>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cV7daQW9odn-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Don't forget to set it back when you are done.\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKT3YBsqy0x4"
   },
   "source": [
    "However, `Function` can behave differently under graph and eager execution. The Python [`print`](https://docs.python.org/3/library/functions.html#print) function is one example of how these two modes differ. Let's check out what happens when you insert a `print` statement to your function and call it repeatedly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BEJeVeBEoGjV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "  print(\"Calculating MSE!\")\n",
    "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
    "  return tf.reduce_mean(sq_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sWTGwX3BzP1"
   },
   "source": [
    "Observe what is printed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T17:16:59.742038Z",
     "iopub.status.busy": "2021-12-08T17:16:59.741430Z",
     "iopub.status.idle": "2021-12-08T17:16:59.788127Z",
     "shell.execute_reply": "2021-12-08T17:16:59.788518Z"
    },
    "id": "3rJIeBg72T9n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE!\n"
     ]
    }
   ],
   "source": [
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLMXk1uxKQ44"
   },
   "source": [
    "Is the output surprising? **`get_MSE` only printed once even though it was called *three* times.**\n",
    "\n",
    "To explain, the `print` statement is executed when `Function` runs the original code in order to create the graph in a process known as \"tracing\". **Tracing captures the TensorFlow operations into a graph, and `print`  is not captured in the graph.**  That graph is then executed for all three calls **without ever running the Python code again**.\n",
    "\n",
    "As a sanity check, let's turn off graph execution to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T17:16:59.793502Z",
     "iopub.status.busy": "2021-12-08T17:16:59.792491Z",
     "iopub.status.idle": "2021-12-08T17:16:59.795172Z",
     "shell.execute_reply": "2021-12-08T17:16:59.794598Z"
    },
    "id": "oFSxRtcptYpe"
   },
   "outputs": [],
   "source": [
    "# Now, globally set everything to run eagerly to force eager execution.\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T17:16:59.799764Z",
     "iopub.status.busy": "2021-12-08T17:16:59.798848Z",
     "iopub.status.idle": "2021-12-08T17:16:59.802679Z",
     "shell.execute_reply": "2021-12-08T17:16:59.803042Z"
    },
    "id": "qYxrAtvzNgHR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE!\n",
      "Calculating MSE!\n",
      "Calculating MSE!\n"
     ]
    }
   ],
   "source": [
    "# Observe what is printed below.\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T17:16:59.807640Z",
     "iopub.status.busy": "2021-12-08T17:16:59.806766Z",
     "iopub.status.idle": "2021-12-08T17:16:59.809118Z",
     "shell.execute_reply": "2021-12-08T17:16:59.808606Z"
    },
    "id": "_Df6ynXcAaup"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUR7qC_bquCn"
   },
   "source": [
    "`print` is a *Python side effect*, and there are other differences that you should be aware of when converting a function into a `Function`. Learn more in the _Limitations_ section of the [Better performance with tf.function](./function.ipynb#limitations) guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTZJfV_tccVp"
   },
   "source": [
    "Note: If you would like to print values in both eager and graph execution, use `tf.print` instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMT_Xf5yKn9o"
   },
   "source": [
    "### Non-strict execution\n",
    "\n",
    "<a id=\"non-strict\"></a>\n",
    "\n",
    "Graph execution only executes the operations necessary to produce the observable effects, which includes:\n",
    "\n",
    "- The return value of the function\n",
    "- Documented well-known side-effects such as:\n",
    "  - Input/output operations, like `tf.print`\n",
    "  - Debugging operations, such as the assert functions in `tf.debugging`\n",
    "  - Mutations of `tf.Variable`\n",
    "\n",
    "This behavior is usually known as \"Non-strict execution\", and differs from eager execution, which steps through all of the program operations, needed or not.\n",
    "\n",
    "In particular, runtime error checking does not count as an observable effect. If an operation is skipped because it is unnecessary, it cannot raise any runtime errors.\n",
    "\n",
    "In the following example, the \"unnecessary\" operation `tf.gather` is skipped during graph execution, so the runtime error `InvalidArgumentError` is not raised as it would be in eager execution. Do not rely on an error being raised while executing a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T17:16:59.815024Z",
     "iopub.status.busy": "2021-12-08T17:16:59.814371Z",
     "iopub.status.idle": "2021-12-08T17:16:59.817370Z",
     "shell.execute_reply": "2021-12-08T17:16:59.817724Z"
    },
    "id": "OdN0nKlUwj7M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def unused_return_eager(x):\n",
    "  # Get index 1 will fail when `len(x) == 1`\n",
    "  tf.gather(x, [1]) # unused \n",
    "  return x\n",
    "\n",
    "try:\n",
    "  print(unused_return_eager(tf.constant([0.0])))\n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "  # All operations are run during eager execution so an error is raised.\n",
    "  print(f'{type(e).__name__}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T17:16:59.822932Z",
     "iopub.status.busy": "2021-12-08T17:16:59.822324Z",
     "iopub.status.idle": "2021-12-08T17:16:59.856141Z",
     "shell.execute_reply": "2021-12-08T17:16:59.856560Z"
    },
    "id": "d80Fob4MwhTs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def unused_return_graph(x):\n",
    "  tf.gather(x, [1]) # unused\n",
    "  return x\n",
    "\n",
    "# Only needed operations are run during graph exection. The error is not raised.\n",
    "print(unused_return_graph(tf.constant([0.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "def6MupG9R0O"
   },
   "source": [
    "###`tf.function` best practices\n",
    "\n",
    "It may take some time to get used to the behavior of `Function`.  To get started quickly, first-time users should play around with decorating toy functions with `@tf.function` to get experience with going from eager to graph execution.\n",
    "\n",
    "*Designing for `tf.function`* may be your best bet for writing graph-compatible TensorFlow programs. Here are some tips:\n",
    "-  Toggle between eager and graph execution early and often with `tf.config.run_functions_eagerly` to pinpoint if/ when the two modes diverge.\n",
    "- Create `tf.Variable`s\n",
    "outside the Python function and modify them on the inside. The same goes for objects that use `tf.Variable`, like `keras.layers`, `keras.Model`s and `tf.optimizers`.\n",
    "- Avoid writing functions that depend on outer Python variables , excluding `tf.Variable`s and Keras objects.\n",
    "- Prefer to write functions which take tensors and other TensorFlow types as input. You can pass in other object types but be careful\n",
    "- Include as much computation as possible under a `tf.function` to maximize the performance gain. For example, decorate a whole training step or the entire training loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViM3oBJVJrDx"
   },
   "source": [
    "## Seeing the speed-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6NHDp7vAKcJ"
   },
   "source": [
    "`tf.function` usually improves the performance of your code, but the amount of speed-up depends on the kind of computation you run. Small computations can be dominated by the overhead of calling a graph. You can measure the difference in performance like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jr7p1BBjauPK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n",
    "def power(x, y):\n",
    "  result = tf.eye(10, dtype=tf.dtypes.int32)\n",
    "  for _ in range(y):\n",
    "    result = tf.matmul(x, result)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ms2yJyAnUYxK",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution: 5.931944398907945\n"
     ]
    }
   ],
   "source": [
    "print(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gUB2mTyRYRAe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution: 1.1497312339488417\n"
     ]
    }
   ],
   "source": [
    "power_as_graph = tf.function(power)\n",
    "print(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100), number=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1Pfo5YwwILi"
   },
   "source": [
    "`tf.function` is commonly used to speed up training loops, and you can learn more about it in Writing a training loop from scratch with Keras.\n",
    "\n",
    "Note: You can also try `tf.function(jit_compile=True)` for a more significant performance boost, especially if your code is heavy on TF control flow and uses many small tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sm0bNFp8PX53"
   },
   "source": [
    "### Performance and trade-offs\n",
    "\n",
    "Graphs can speed up your code, but the process of creating them has some overhead. For some functions, the creation of the graph takes more time than the execution of the graph. **This investment is usually quickly paid back with the performance boost of subsequent executions, but it's important to be aware that the first few  steps of any large model training can be slower due to tracing.**\n",
    "\n",
    "No matter how large your model, you want to avoid tracing frequently. The `tf.function` guide discusses how to set input specifications and use tensor arguments to avoid retracing.  If you find you are getting unusually poor performance, it's a good idea to check if you are retracing accidentally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4InDaTjwmBA"
   },
   "source": [
    "## When is a `Function` tracing?\n",
    "\n",
    "To figure out when your `Function` is tracing, add a `print` statement to its code. As a rule of thumb, `Function` will execute the `print` statement every time it traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T17:17:03.133468Z",
     "iopub.status.busy": "2021-12-08T17:17:03.132399Z",
     "iopub.status.idle": "2021-12-08T17:17:03.170874Z",
     "shell.execute_reply": "2021-12-08T17:17:03.171227Z"
    },
    "id": "hXtwlbpofLgW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def a_function_with_python_side_effect(x):\n",
    "  print(\"Tracing!\") # An eager-only side effect.\n",
    "  return x * x + tf.constant(2)\n",
    "\n",
    "# This is traced the first time.\n",
    "print(a_function_with_python_side_effect(tf.constant(2)))\n",
    "# The second time through, you won't see the side effect.\n",
    "print(a_function_with_python_side_effect(tf.constant(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T17:17:03.177126Z",
     "iopub.status.busy": "2021-12-08T17:17:03.176473Z",
     "iopub.status.idle": "2021-12-08T17:17:03.191253Z",
     "shell.execute_reply": "2021-12-08T17:17:03.191617Z"
    },
    "id": "inzSg8yzfNjl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "Tracing!\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# This retraces each time the Python argument changes,\n",
    "# as a Python argument could be an epoch count or other\n",
    "# hyperparameter.\n",
    "print(a_function_with_python_side_effect(2))\n",
    "print(a_function_with_python_side_effect(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtN8NW6AfKye"
   },
   "source": [
    "New Python arguments always trigger the creation of a new graph, hence the extra tracing.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro_to_graphs.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
